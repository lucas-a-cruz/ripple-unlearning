# Pipeline de Desaprendizagem para Dano Colateral

Este diret√≥rio cont√©m uma documenta√ß√£o para o pipeline customizado, projetado para executar experimentos de desaprendizagem focados em medir o "dano colateral" em um benchmark pr√©-existente. Diferente do pipeline de *Domain Unlearning*, este n√£o gera novo conte√∫do, mas utiliza o arquivo `data/datasets/collateral_damage_probes.jsonl`.

## üöÄ In√≠cio R√°pido

O pipeline √© orquestrado pelo script `run-collateral-damage-unlearning.sh`.

```bash
# Exemplo b√°sico:
# Executa um experimento no grupo "michael_jordan", marcando 1 entidade para esquecer.
# Usa o modelo e o trainer padr√£o (Llama-3.2-1B-Instruct e GradAscent).
bash third_party/scripts/run-collateral-damage-unlearning.sh "michael_jordan" 1

# Exemplo avan√ßado:
# Executa um experimento no grupo "lincoln", marcando 2 entidades para esquecer,
# usando um modelo e trainer customizados.
bash third_party/scripts/run-collateral-damage-unlearning.sh "lincoln" 2 "meta-llama/Meta-Llama-3-8B-Instruct" "NPO"
```

## üìã Vis√£o Geral

O objetivo deste pipeline √© facilitar a avalia√ß√£o do impacto que o desaprendizado de uma entidade (`E_t`) tem sobre o conhecimento do modelo a respeito de entidades relacionadas, mas distintas (`E_a`).

O processo consiste nos seguintes passos, automatizados pelos scripts:

1.  **Prepara√ß√£o do Dataset**: O script `third_party/src/collateral_damage/run_unlearning_experiment.py` l√™ o arquivo `collateral_damage_probes.jsonl`, filtra pelo `group_id` especificado, e divide as entidades do grupo em um conjunto `forget` e um `retain`.
2.  **Cria√ß√£o de Configura√ß√µes**: Gera dinamicamente os arquivos de configura√ß√£o `.yaml` que o framework `open-unlearning` precisa para localizar os dados e configurar o experimento.
3.  **Execu√ß√£o do Desaprendizado**: Invoca o script `third_party/src/train.py` para executar o algoritmo de desaprendizagem no modelo especificado.
4.  **Resumo**: Ao final, exibe um resumo dos artefatos gerados e sugere o comando para a etapa de avalia√ß√£o.

## üîß Argumentos do Script

O script `run-collateral-damage-unlearning.sh` aceita os seguintes argumentos:

1.  `GROUP_ID` (Obrigat√≥rio): A categoria do seu benchmark que ser√° o foco do experimento (ex: "michael_jordan", "lincoln", "apple").
2.  `NUM_FORGET` (Obrigat√≥rio): O n√∫mero de entidades √∫nicas dentro do `GROUP_ID` que ser√£o colocadas no conjunto `forget`. As restantes ir√£o para o `retain`.
3.  `MODEL` (Opcional): O nome do modelo do Hugging Face a ser usado. O padr√£o √© `meta-llama/Llama-3.2-1B-Instruct` para ser compat√≠vel com GPUs de ~16GB.
4.  `TRAINER` (Opcional): O m√©todo de desaprendizagem a ser usado. O padr√£o √© `GradAscent`.

### Hiperpar√¢metros de Treinamento

Para um controle mais refinado, voc√™ pode executar o script Python diretamente e passar os seguintes argumentos para ajustar os hiperpar√¢metros de treinamento:

*   `--learning_rate`: A taxa de aprendizado (padr√£o: `1e-5`).
*   `--num_train_epochs`: N√∫mero de √©pocas de treinamento (padr√£o: `5`).
*   `--per_device_train_batch_size`: Batch size por GPU (padr√£o: `4`).
*   `--gradient_accumulation_steps`: Passos de acumula√ß√£o de gradiente (padr√£o: `4`).

**Exemplo de uso avan√ßado (executando o script Python diretamente):**
```bash
python third_party/src/collateral_damage/run_unlearning_experiment.py \
  --group_id "lincoln" \
  --num_forget 2 \
  --model "meta-llama/Meta-Llama-3-8B-Instruct" \
  --learning_rate 5e-6 \
  --num_train_epochs 3
```

## ‚öôÔ∏è Otimiza√ß√£o para Baixo Consumo de VRAM

Os scripts foram configurados para rodar em GPUs com 16GB de VRAM, utilizando as seguintes otimiza√ß√µes:

*   **Modelo Padr√£o Pequeno**: `Llama-3.2-1B-Instruct`.
*   **Batch Size M√≠nimo**: `per_device_train_batch_size` √© definido como `1`.
*   **Acumula√ß√£o de Gradiente**: `gradient_accumulation_steps` √© `4` para simular um batch size maior sem o custo de mem√≥ria.
*   **Gradient Checkpointing**: Ativado por padr√£o (`true`) para economizar uma quantidade significativa de VRAM.
*   **Otimizador Paginado**: O framework utiliza por padr√£o o `paged_adamw_32bit`, que descarrega o estado do otimizador para a RAM da CPU.

## üìä Pr√≥ximos Passos: Avalia√ß√£o

Ap√≥s a conclus√£o do script de desaprendizagem, um modelo ser√° salvo em `saves/unlearn/<run_name>/`. O passo mais importante da sua pesquisa √© avaliar este modelo para medir o dano colateral.

Use o comando sugerido no final da execu√ß√£o do script para iniciar a avalia√ß√£o:

```bash
# Exemplo de comando de avalia√ß√£o
python third_party/src/eval.py \
    experiment=eval/tofu/default \
    model=Llama-3.2-1B-Instruct \
    model.model_args.pretrained_model_name_or_path=saves/unlearn/michael_jordan_1forget_20251206_120000 \
    task_name=michael_jordan_1forget_20251206_120000_eval
```

A an√°lise dos resultados desta avalia√ß√£o (especialmente a performance no conjunto `retain`) indicar√° a magnitude do dano colateral.
