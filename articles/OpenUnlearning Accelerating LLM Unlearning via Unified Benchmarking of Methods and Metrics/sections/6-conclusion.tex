\section{Conclusion}
% \vspace{-5pt}
The field of LLM unlearning has faced challenges due to fragmented methodologies and inconsistent evaluations. To address this, we introduced \ou{}, a standardized and extensible framework that unifies research efforts by integrating 13 unlearning algorithms, 16 evaluation metrics, and 3 major benchmarks. This comprehensive platform enabled us to conduct a novel meta-evaluation of unlearning metrics, assessing their faithfulness and robustness, and to perform large-scale benchmarking of unlearning methods. Our meta-evaluation identified Extraction Strength (ES) and Exact Memorization (EM) as particularly reliable metrics, with Truth Ratio also showing high faithfulness. \wrapped{Benchmarking revealed SimNPO and RMU as strong performers, though we also observed significant sensitivities in ranking.} At the same time \ou{}, by providing a common ground and releasing numerous model checkpoints, establishes a clear pathway for the community towards more rigorous, reproducible, and accelerated development of robust unlearning techniques and evaluation protocols, ultimately fostering safer AI deployments. 
% Future work should focus on creating more realistic benchmarks and continuously refining evaluation standards.

\section{Acknowledgments}

We thank all contributors for adding new unlearning methods and metrics. We also appreciate their continued support through active use of the repository and valuable feedback that helps improve the codebase. We also acknowledge the IESL lab at University of Massachusetts Amherst for providing compute resources for this work. PM is supported by funding from the DARPA GARD program and OpenAIâ€™s Cybersecurity Grant Program.
